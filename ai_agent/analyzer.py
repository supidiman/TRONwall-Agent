import os
import json
import google.generativeai as genai
import time
import sys
from dotenv import load_dotenv

# --- 1. AYARLAR & IMPORTLAR ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# .env dosyasÄ±nÄ± gÃ¼venli yÃ¼kle
dotenv_path = os.path.join(parent_dir, '.env')
load_dotenv(dotenv_path)
api_key = os.getenv("GEMINI_API_KEY")

if not api_key:
    raise ValueError("API Key bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")

genai.configure(api_key=api_key, transport="rest")




# Whitelist ModÃ¼lÃ¼
try:
    from rag_memory.whitelist_manager import WhitelistManager
    whitelist = WhitelistManager()
    print("Whitelist ModÃ¼lÃ¼ Devrede.")
except ImportError:
    whitelist = None
    print("Whitelist yÃ¼klenemedi.")


# RAG (HafÄ±za) ModÃ¼lÃ¼
try:
    from rag_memory.retriever import KnowledgeBase
    kb = KnowledgeBase()
except ImportError:
    kb = None

# LEARNER (Ã–ÄŸrenme) ModÃ¼lÃ¼
try:
    from rag_memory.learner import AutoLearner
    learner = AutoLearner()
    print("Ã–ÄŸrenme ModÃ¼lÃ¼ (Learner) Devrede.")
except ImportError:
    print(" Ã–ÄŸrenme modÃ¼lÃ¼ yÃ¼klenemedi.")
    learner = None

TRONWALL_SYSTEM_PROMPT = """
Sen TRONwall adÄ±nda otonom bir gÃ¼venlik analizcisisin. 
GÃ¶revin: Log girdisini analiz et ve tehditleri tespit et.

Kurallar:
1. SADECE JSON Ã§Ä±ktÄ±sÄ± ver.
2. Ã‡Ä±ktÄ± formatÄ±:
{
  "attack_detected": boolean, 
  "attack_type": "string (Ã¶rn: SQL Injection, XSS, DDoS, None)",
  "confidence_score": number (0.0 - 1.0),
  "suggested_action": "string",
  "explanation": "string"
}
"""

def analyze_log(log_entry, retry_count=0):
    """
    Logu analiz eder. Hata alÄ±rsa yÃ¶netir.
    """
    print(f"\n[TRONwall] Analiz: {log_entry[:50]}...")


    # --- ADIM 0: BEYAZ LÄ°STE KONTROLÃœ (Whitelist) ---
    # EÄŸer gÃ¼venliyse, ne AI'ya ne de HafÄ±zaya sorma. Direkt geÃ§ir.
    if whitelist:
        is_safe, reason = whitelist.is_whitelisted(log_entry)
        if is_safe:
            print(f"ğŸ›¡ï¸ WHITELIST: GÃ¼venli olarak iÅŸaretlendi. ({reason})")
            return {
                "attack_detected": False,
                "attack_type": "None",
                "confidence_score": 1.0,
                "suggested_action": "allow",
                "explanation": f"YÃ¶netici tarafÄ±ndan beyaz listeye alÄ±nmÄ±ÅŸ: {reason}"
            }
            
    # --- ADIM 1: HAFIZA KONTROLÃœ (RAG) ---
    if kb:
        matches = kb.search_knowledge(log_entry)
        if matches:
            print(" HAFIZADA BULUNDU! (Gemini AtlandÄ±)")
            best = matches[0]
            
            # --- GÃœVENLÄ° VERÄ° OKUMA (KeyError Ã‡Ã¶zÃ¼mÃ¼) ---
            # VeritabanÄ±nda bazÄ± alanlar eksik olsa bile kod Ã§Ã¶kmesin diye .get() kullanÄ±yoruz.
            
            # Action verisini gÃ¼venli al, yoksa 'block_ip' yap
            rule_template = best.get('rule_template', {})
            action = rule_template.get('action', 'block_ip')
            
            # SaldÄ±rÄ± adÄ±nÄ± gÃ¼venli al
            attack_name = best.get('attack_name', best.get('name', 'Known Attack'))
            
            return {
                "attack_detected": True,
                "attack_type": attack_name,
                "confidence_score": 1.0,
                "suggested_action": action,
                "explanation": f"RAG veritabanÄ±nda kayÄ±tlÄ± tehdit. Desen: {best.get('matched_pattern', 'N/A')}"
            }

    # --- ADIM 2: YAPAY ZEKA ANALÄ°ZÄ° (AI) ---
    print("Bilinmiyor. Gemini'ye soruluyor...")
    
    model = genai.GenerativeModel(
        model_name='gemini-2.5-flash', 
        system_instruction=TRONWALL_SYSTEM_PROMPT,
        generation_config={"response_mime_type": "application/json", "temperature": 0.1}
    )

    try:
        response = model.generate_content(log_entry)
        result = json.loads(response.text)
        
        # --- ADIM 3: OTOMATÄ°K Ã–ÄRENME (SELF-LEARNING) ---
        if result.get("attack_detected") and learner:
            print(" YENÄ° SALDIRI TESPÄ°T EDÄ°LDÄ°! HafÄ±zaya kaydediliyor...")
            
            learner.learn_new_attack(
                attack_type=result.get("attack_type"),
                log_pattern=log_entry,
                risk_level="HIGH"
            )
            
        return result

    except Exception as e:
        # KOTA HATASI YÃ–NETÄ°MÄ° (Rate Limit Fix)
        if "429" in str(e) or "Quota" in str(e):
            if retry_count < 3:
                wait_time = 20
                print(f" API KotasÄ± (429)! {wait_time} saniye bekleniyor... (Deneme {retry_count+1})")
                time.sleep(wait_time)
                return analyze_log(log_entry, retry_count + 1)
        
        print(f"HATA: {e}")
        return {"attack_detected": False, "error": str(e)}

if __name__ == "__main__":
    # Test amaÃ§lÄ±
    test_log = "SELECT * FROM users WHERE admin = '1' OR '1'='1'"
    analyze_log(test_log)